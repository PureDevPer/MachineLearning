{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Xp = np.array([\n",
    "\t[4, 2, 2, 3, 4, 6, 3, 8],\n",
    "\t[1, 4, 3, 6, 4, 2, 2, 3],\n",
    "\t[0, 1, 1, 0, -1, 0, 1, 0]\n",
    "\t])\n",
    "\n",
    "Xn = np.array([\n",
    "\t[9, 6, 9, 8, 10],\n",
    "\t[10, 8, 5, 7, 8],\n",
    "\t[1, 0, 0, 1, -1]\n",
    "\t])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. write code to compute the class specific means of data matrices Xp and Xn. \n",
    "Your code needs to return the mean as a {\\bf column} vector.\n",
    "2. use your code, compute the mean of matrices Xp and Xn given in the problem setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp_mean = np.mean(Xp, axis=1)\n",
    "Xn_mean = np.mean(Xn, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xp_mean:  [4.    3.125 0.25 ]\n",
      "Xn_mean:  [8.4 7.6 0.2]\n"
     ]
    }
   ],
   "source": [
    "print('Xp_mean: ', Xp_mean)\n",
    "print('Xn_mean: ', Xn_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. write code to compute the class specific covariance matrices of data matrices Xp and Xn.\n",
    "4. use your code, compute the class specific covariance matrices of data matrices Xp and Xn given in the problem setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xp1 = np.zeros( (len(Xp), len(Xp[0]) ))\n",
    "for i in range(len(Xp[0])):\n",
    "\tXp1[:,i] = Xp[:,i] - Xp_mean\n",
    "\n",
    "Xn1 = np.zeros( (len(Xn), len(Xn[0]) ))\n",
    "for i in range(len(Xn[0])):\n",
    "\tXn1[:,i] = Xn[:,i] - Xn_mean\n",
    "\n",
    "Xp_Cov = Xp1.dot(Xp1.T)\n",
    "Xn_Cov = Xn1.dot(Xn1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xp_Cov:  [[30.    -6.    -5.   ]\n",
      " [-6.    16.875 -1.25 ]\n",
      " [-5.    -1.25   3.5  ]]\n",
      "Xn_Cov:  [[ 9.2 -0.2 -1.4]\n",
      " [-0.2 13.2  1.4]\n",
      " [-1.4  1.4  2.8]]\n"
     ]
    }
   ],
   "source": [
    "print('Xp_Cov: ', Xp_Cov)\n",
    "print('Xn_Cov: ', Xn_Cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance Matrix\n",
    "$$\n",
    "    C = XX^T = \\sum_{k=1}^n(X_k-mean)(X_k-mean)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. write code to compute between class scattering matrix Sb.\n",
    "6. use your code, compute Sb for data given in the problem setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.append(Xp, Xn, axis=1)\n",
    "total_Mean = np.mean(tmp, axis=1)\n",
    "Sb_Xp = len(total_Mean)*((Xp_mean.reshape(len(Xp_mean),1) - total_Mean.reshape(len(total_Mean),1)).dot((Xp_mean.reshape(len(Xp_mean),1) - total_Mean.reshape(len(total_Mean),1)).T))\n",
    "Sb_Xn = len(total_Mean)*((Xn_mean.reshape(len(Xn_mean),1) - total_Mean.reshape(len(total_Mean),1)).dot((Xn_mean.reshape(len(Xn_mean),1) - total_Mean.reshape(len(total_Mean),1)).T))\n",
    "Sb = Sb_Xp + Sb_Xn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sb_Xp:  [[ 8.59171598e+00  8.73816568e+00 -9.76331361e-02]\n",
      " [ 8.73816568e+00  8.88711169e+00 -9.92973373e-02]\n",
      " [-9.76331361e-02 -9.92973373e-02  1.10946746e-03]]\n",
      "Sb_Xn:  [[ 2.19947929e+01  2.23697041e+01 -2.49940828e-01]\n",
      " [ 2.23697041e+01  2.27510059e+01 -2.54201183e-01]\n",
      " [-2.49940828e-01 -2.54201183e-01  2.84023669e-03]]\n",
      "Sb:  [[ 3.05865089e+01  3.11078698e+01 -3.47573964e-01]\n",
      " [ 3.11078698e+01  3.16381176e+01 -3.53498521e-01]\n",
      " [-3.47573964e-01 -3.53498521e-01  3.94970414e-03]]\n"
     ]
    }
   ],
   "source": [
    "print('Sb_Xp: ', Sb_Xp)\n",
    "print('Sb_Xn: ', Sb_Xn)\n",
    "print('Sb: ', Sb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between class scattering matrix\n",
    "$$\n",
    "S_b= \\frac{1}{n} \\sum(\\mu_+-\\mu_-)(\\mu_+-\\mu_-)^T\n",
    "$$\n",
    "where\n",
    "mean of positive data\n",
    "$$\n",
    "\\mu_+ = \\frac{1}{n_+} \\sum_{i}x_i^+\n",
    "$$\n",
    "mean of negative data\n",
    "$$\n",
    "\\mu_- = \\frac{1}{n_-} \\sum_{i} x_i^-\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, mean of real data (Xp and Xn)\n",
    "$$ \\mu_+ $$ \n",
    "mean of total data $$ \\mu_- $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate Sb, array Xp and Xn are combined. And then, Sb_Xp and Sb_Xn are calculated respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. write code to compute the within class scattering matrix Sw.\n",
    "8. use your code, compute Sw for data given in the problem setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sw = Xp_Cov + Xn_Cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sw:  [[39.2   -6.2   -6.4  ]\n",
      " [-6.2   30.075  0.15 ]\n",
      " [-6.4    0.15   6.3  ]]\n"
     ]
    }
   ],
   "source": [
    "print('Sw: ', Sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within class scattering matrix\n",
    "$$\n",
    "S_w = \\frac {n_+}{n_-}S_+ + \\frac {n_+}{n_-}S_-\n",
    "$$\n",
    "where covariance matrix of positive data\n",
    "$$\n",
    "S_+ = \\frac{1}{n_+} \\sum_{i}(x_i^+ - \\mu_+) (x_i^+ - \\mu_+)^T\n",
    "$$\n",
    "covariance matrix of negative data\n",
    "$$\n",
    "S_+ = \\frac{1}{n_-} \\sum_{i}(x_i^+ - \\mu_-) (x_i^+ - \\mu_-)^T\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can use covariance matrix we already calculated above in order for Sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. write code to compute the LDA projection by solving the generalized eigenvalue decomposition problem. [use function numpy.linalg.eig]\n",
    "10. use your code, compute the LDA projection for the data given in the problem setting.  You should see that the second eigenvalue is zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalue:  [2.43615153e+00 3.14701096e-16 4.05475959e-18]\n",
      "Second eigenvalue:  3.1470109648107917e-16\n",
      "We can see that the second eigenvalue is almost zero like given instruction\n"
     ]
    }
   ],
   "source": [
    "eigenvalue, eigenvector = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))\n",
    "\n",
    "# Sorting eigenvalue and eigenvector from highest to lowest\n",
    "arrNum = np.argsort(eigenvalue)[::-1]\n",
    "eigenvector_sort = eigenvector[:,arrNum]\n",
    "eigenvalue_sort = eigenvalue[arrNum]\n",
    "\n",
    "v = eigenvector_sort[:, :1]\n",
    "\n",
    "print(\"eigenvalue: \", eigenvalue_sort)\n",
    "print(\"Second eigenvalue: \", eigenvalue_sort[1])\n",
    "print(\"We can see that the second eigenvalue is almost zero like given instruction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 eigenvalues are 2.43615153e+00 3.14701096e-16 4.05475959e-18. Like a given instruction, we can see that the second eigenvalue is almost zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalized eigenvalue problem.\n",
    "Let's solve \n",
    "$$\n",
    "\\lambda S_wv = S_bv\n",
    "$$\n",
    "When Sw is invertible v is eigenvector of the top eigenvalue for matrix \n",
    "$$ S_w^{-1}S_b $$ with $$\\lambda$$ being the corresponding eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, in order to get eigenvalue and eigenvector, we use \n",
    "$$\n",
    "\\lambda S_wv = S_bv\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. collect all previous steps, write a function with name mybLDA_train to perform binary LDA, which takes inputs of two data matrices Xp and Xn assuming column data, and return the optimal LDA projection direction as a unit vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mybLDA_train(Xp, Xn):\n",
    "\tXp_mean = np.mean(Xp, axis=1)\n",
    "\tXn_mean = np.mean(Xn, axis=1)\n",
    "\t\n",
    "\tXp1 = np.zeros( (len(Xp), len(Xp[0]) ))\n",
    "\tfor i in range(len(Xp[0])):\n",
    "\t\tXp1[:,i] = Xp[:,i] - Xp_mean\n",
    "\n",
    "\tXn1 = np.zeros( (len(Xn), len(Xn[0]) ))\n",
    "\tfor i in range(len(Xn[0])):\n",
    "\t\tXn1[:,i] = Xn[:,i] - Xn_mean\n",
    "\n",
    "\tXp_Cov = Xp1.dot(Xp1.T)\n",
    "\tXn_Cov = Xn1.dot(Xn1.T)\n",
    "\n",
    "\ttmp = np.append(Xp, Xn, axis=1)\n",
    "\ttotal_Mean = np.mean(tmp, axis=1)\n",
    "\tSb_Xp = len(total_Mean)*((Xp_mean.reshape(len(Xp_mean),1) - total_Mean.reshape(len(total_Mean),1)).dot((Xp_mean.reshape(len(Xp_mean),1) - total_Mean.reshape(len(total_Mean),1)).T))\n",
    "\tSb_Xn = len(total_Mean)*((Xn_mean.reshape(len(Xn_mean),1) - total_Mean.reshape(len(total_Mean),1)).dot((Xn_mean.reshape(len(Xn_mean),1) - total_Mean.reshape(len(total_Mean),1)).T))\n",
    "\tSb = Sb_Xp + Sb_Xn\n",
    "\n",
    "\tSw = Xp_Cov + Xn_Cov\n",
    "\n",
    "\teigenvalue, eigenvector = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))\n",
    "\n",
    "\tarrNum = np.argsort(eigenvalue)[::-1]\n",
    "\teigenvector_sort = eigenvector[:,arrNum]\n",
    "\teigenvalue_sort = eigenvalue[arrNum]\n",
    "\n",
    "\tbestRep = eigenvalue_sort[0] / np.sum(eigenvalue)\n",
    "\tbestRepVector = eigenvector_sort[:,:1]\n",
    "\t# Choose best 1 eigenvectors\n",
    "\tprojectionDirection = eigenvector_sort[:, :1]\n",
    "\n",
    "\treturn projectionDirection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. write a function with name mybLDA_classify  which takes a data matrix X and a projection direction v,  returns a row vector r that has size as the number of rows in X, and r_i =+1 if the ith column of X is from the class as in Xp, and r_i =-1 if the ith column in X is from the class as in Xn.\n",
    "13. Run your function, mybLDA_train, on the data given in the problem setting, and then use the obtained projection direction and your function mybLDA_classify to classify the following data setùëã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([\n",
    "\t[1.3, 2.4, 6.7, 2.2, 3.4, 3.2],\n",
    "\t[8.1, 7.6, 2.1, 1.1, 0.5, 7.4],\n",
    "\t[-1, 2, 3, 2, 0, 2]\n",
    "\t])\n",
    "v = eigenvector_sort[:, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mybLDA_classify(X, v):\n",
    "\tXp_lda = (Xp.T).dot(v)\n",
    "\tXn_lda = (Xn.T).dot(v)\n",
    "\tX_lda = (X.T).dot(v)\n",
    "\tmean = (np.mean(Xp_lda) + np.mean(Xn_lda))/2\n",
    "\tr = np.zeros((len(X_lda),1))\n",
    "\n",
    "\tfor i in range(len(X_lda)):\n",
    "\t\tif X_lda[i] < mean:\n",
    "\t\t\tr[i] = 1\n",
    "\t\telse:\n",
    "\t\t\tr[i] = -1\n",
    "\n",
    "\treturn r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets' transform the test data, which is array X, on the new subspace. Therefore, $$Xv$$To find threshold in order for which columns are from, I use mean value. So, I calculated total mean of Xp and Xn. A given array A and v, which is eigenvector, can be multiplied. This is called X_lda. If total mean of Xp and Xn is greater than X_lda, then r_i = +1, which means that the ith column of X is from the class as in Xp. Otherwise, r_i = -1, which indicates the ith column of X is from the class as in Xn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is entier code for homework 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1.  1.  1.  1. -1.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def getXp():\n",
    "\tXp = np.array([\n",
    "\t[4, 2, 2, 3, 4, 6, 3, 8],\n",
    "\t[1, 4, 3, 6, 4, 2, 2, 3],\n",
    "\t[0, 1, 1, 0, -1, 0, 1, 0]\n",
    "\t])\n",
    "\n",
    "\treturn Xp\n",
    "\n",
    "def getXn():\n",
    "\tXn = np.array([\n",
    "\t[9, 6, 9, 8, 10],\n",
    "\t[10, 8, 5, 7, 8],\n",
    "\t[1, 0, 0, 1, -1]\n",
    "\t])\n",
    "\n",
    "\treturn Xn\n",
    "\n",
    "def getX():\n",
    "\tX = np.array([\n",
    "\t[1.3, 2.4, 6.7, 2.2, 3.4, 3.2],\n",
    "\t[8.1, 7.6, 2.1, 1.1, 0.5, 7.4],\n",
    "\t[-1, 2, 3, 2, 0, 2]\n",
    "\t])\n",
    "\n",
    "\treturn X\n",
    "\n",
    "def mybLDA_train(Xp, Xn):\n",
    "\tXp_mean = np.mean(Xp, axis=1)\n",
    "\tXn_mean = np.mean(Xn, axis=1)\n",
    "\t\n",
    "\tXp1 = np.zeros( (len(Xp), len(Xp[0]) ))\n",
    "\tfor i in range(len(Xp[0])):\n",
    "\t\tXp1[:,i] = Xp[:,i] - Xp_mean\n",
    "\n",
    "\tXn1 = np.zeros( (len(Xn), len(Xn[0]) ))\n",
    "\tfor i in range(len(Xn[0])):\n",
    "\t\tXn1[:,i] = Xn[:,i] - Xn_mean\n",
    "\n",
    "\tXp_Cov = Xp1.dot(Xp1.T)\n",
    "\tXn_Cov = Xn1.dot(Xn1.T)\n",
    "\n",
    "\ttmp = np.append(Xp, Xn, axis=1)\n",
    "\ttotal_Mean = np.mean(tmp, axis=1)\n",
    "\tSb_Xp = len(total_Mean)*((Xp_mean.reshape(len(Xp_mean),1) - total_Mean.reshape(len(total_Mean),1)).dot((Xp_mean.reshape(len(Xp_mean),1) - total_Mean.reshape(len(total_Mean),1)).T))\n",
    "\tSb_Xn = len(total_Mean)*((Xn_mean.reshape(len(Xn_mean),1) - total_Mean.reshape(len(total_Mean),1)).dot((Xn_mean.reshape(len(Xn_mean),1) - total_Mean.reshape(len(total_Mean),1)).T))\n",
    "\tSb = Sb_Xp + Sb_Xn\n",
    "\n",
    "\tSw = Xp_Cov + Xn_Cov\n",
    "\n",
    "\teigenvalue, eigenvector = np.linalg.eig(np.linalg.inv(Sw).dot(Sb))\n",
    "\n",
    "\tarrNum = np.argsort(eigenvalue)[::-1]\n",
    "\teigenvector_sort = eigenvector[:,arrNum]\n",
    "\teigenvalue_sort = eigenvalue[arrNum]\n",
    "\n",
    "\tbestRep = eigenvalue_sort[0] / np.sum(eigenvalue)\n",
    "\tbestRepVector = eigenvector_sort[:,:1]\n",
    "\t# Choose best 1 eigenvectors\n",
    "\tprojectionDirection = eigenvector_sort[:, :1]\n",
    "\n",
    "\treturn projectionDirection\n",
    "\n",
    "def mybLDA_classify(X, v):\n",
    "\tXp_lda = (getXp().T).dot(v)\n",
    "\tXn_lda = (getXn().T).dot(v)\n",
    "\tX_lda = (X.T).dot(v)\n",
    "\tmean = (np.mean(Xp_lda) + np.mean(Xn_lda))/2\n",
    "\tr = np.zeros((len(X_lda),1))\n",
    "\n",
    "\tfor i in range(len(X_lda)):\n",
    "\t\tif X_lda[i] < mean:\n",
    "\t\t\tr[i] = 1\n",
    "\t\telse:\n",
    "\t\t\tr[i] = -1\n",
    "\n",
    "\treturn r.T\n",
    "\n",
    "\n",
    "def main():\n",
    "\tXp = getXp()\n",
    "\tXn = getXn()\n",
    "\tX = getX()\n",
    "\tv = mybLDA_train(Xp, Xn)\n",
    "\tr = mybLDA_classify(X, v)\n",
    "\tprint(r)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
